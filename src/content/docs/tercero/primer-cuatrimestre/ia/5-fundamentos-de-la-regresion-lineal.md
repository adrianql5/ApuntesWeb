---
title: "Fundamentos de la RegresiÃ³n Lineal"
---

Copyright (c) 2025 AdriÃ¡n Quiroga Linares Lectura y referencia permitidas; reutilizaciÃ³n y plagio prohibidos

# 5.1 Â¿QuÃ© es el Aprendizaje AutomÃ¡tico?
Un programa informÃ¡tico **aprende** de la **experiencia E** en relaciÃ³n a una **tarea T**, utilizando una **medida de rendimiento P**, si mejora sus prestaciones, medidas mediante **P**, en la realizaciÃ³n de la tarea **T** a travÃ©s de la experiencia **E**.

Esto suena complicado, pero es simple. Vamos a desglosarlo:

## Ejemplo: Programa que juega a las damas

| Componente                      | Significado                                 | En el ejemplo de damas                   |
| ------------------------------- | ------------------------------------------- | ---------------------------------------- |
| **T (Tarea)**                   | Lo que queremos que haga el programa        | Jugar a las damas                        |
| **E (Experiencia)**             | Los datos o situaciones con las que aprende | Jugar muchas partidas                    |
| **P (Performance/Rendimiento)** | CÃ³mo medimos si lo hace bien                | Probabilidad de ganar la prÃ³xima partida |

**En resumen**: El programa **aprende a jugar mejor a las damas** (T) jugando muchas partidas (E), y sabemos que aprende porque cada vez gana mÃ¡s veces (P).

# 5.2 Â¿Por quÃ© es importante el Aprendizaje AutomÃ¡tico?
1. **Hacer viables ciertas aplicaciones** que serÃ­an imposibles de programar manualmente
   - Ejemplo: Reconocimiento facial con millones de variaciones

2. **Construir una IA de propÃ³sito general**
   - En lugar de programar reglas especÃ­ficas, el sistema aprende de forma general

3. **Avances tecnolÃ³gicos actuales**:
   - Mayor potencia de cÃ¡lculo
   - Mayor capacidad de almacenamiento
   - Disponibilidad masiva de datos
   - Mejores algoritmos


# 5.3 Estrategias de Aprendizaje
Imagina que estÃ¡s enseÃ±ando a un niÃ±o a identificar frutas:

## 5.3.1 Aprendizaje Supervisado
**DefiniciÃ³n**: Durante el entrenamiento, le dices al sistema **exactamente quÃ© respuesta es correcta** para cada ejemplo.

**AnalogÃ­a**: Como un profesor que corrige un examen mostrando la respuesta correcta.

**Ejemplo**:
```
Entrada: [Imagen de manzana] â†’ Etiqueta: "Manzana" âœ…
Entrada: [Imagen de naranja] â†’ Etiqueta: "Naranja" âœ…
Entrada: [Imagen de plÃ¡tano] â†’ Etiqueta: "PlÃ¡tano" âœ…
```

El sistema aprende: "Cuando vea esta forma y color â†’ es una manzana"


## 5.3.2 Aprendizaje No Supervisado
**DefiniciÃ³n**: Le das datos al sistema **SIN etiquetas**, y Ã©l debe encontrar patrones por sÃ­ mismo.

**AnalogÃ­a**: Como darle a un niÃ±o una caja de botones y pedirle que los agrupe como quiera.

**Ejemplo**:
```
Le das: [ğŸ, ğŸŠ, ğŸ, ğŸŒ, ğŸŠ, ğŸ, ğŸŒ]

El sistema agrupa:
Grupo 1 (rojos, redondos): ğŸğŸğŸ
Grupo 2 (naranjas, redondos): ğŸŠğŸŠ
Grupo 3 (amarillos, alargados): ğŸŒğŸŒ
```

**Aplicaciones reales**:
- SegmentaciÃ³n de clientes (agrupar clientes similares)
- DetecciÃ³n de anomalÃ­as
- CompresiÃ³n de datos

## 5.3.3 Aprendizaje por Refuerzo
**DefiniciÃ³n**: El sistema recibe **seÃ±ales de recompensa o castigo** segÃºn sus acciones, pero no se le dice explÃ­citamente quÃ© hacer.

**AnalogÃ­a**: Como entrenar a un perro con premios cuando hace algo bien.

**Ejemplo: Robot aprendiendo a caminar**
```
AcciÃ³n: Da un paso hacia adelante
Resultado: No se cae
SeÃ±al: +10 puntos âœ… (recompensa)

AcciÃ³n: Se inclina demasiado
Resultado: Se cae
SeÃ±al: -50 puntos âŒ (castigo)
```

**Aplicaciones reales**:
- Videojuegos (AlphaGo)
- Robots industriales
- VehÃ­culos autÃ³nomos

# 5.4 Tipos de Problemas en Aprendizaje Supervisado

## 5.4 Problemas de RegresiÃ³n
**Objetivo**: Predecir un **valor numÃ©rico continuo**.

**DefiniciÃ³n simple**: Encontrar la funciÃ³n (curva/lÃ­nea) que mejor se ajuste a los datos.

**Ejemplo visual**:
```
Precio de casas segÃºn tamaÃ±o

Precio (â‚¬)
300kâ”‚                     â— (140mÂ², 280kâ‚¬)
250kâ”‚               â—     
200kâ”‚          â—          
150kâ”‚     â—               
100kâ”‚  â—                  Aprendemos la lÃ­nea
 50kâ”‚                     que mejor ajusta
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> TamaÃ±o (mÂ²)
    50  70  90  110  130
```

**Lo que aprende el algoritmo**: La lÃ­nea que mejor predice el precio segÃºn el tamaÃ±o.

**Pregunta tÃ­pica**: "Â¿CuÃ¡nto costarÃ¡ una casa de 120mÂ²?" â†’ Respuesta: ~250,000â‚¬

**Otros ejemplos**:
- Predecir temperatura maÃ±ana
- Estimar ventas del prÃ³ximo mes
- Predecir edad de una persona por su foto

## 5.4.2 Problemas de ClasificaciÃ³n
**Objetivo**: Asignar datos a **categorÃ­as discretas** (clases).

**DefiniciÃ³n simple**: Encontrar la frontera que separa diferentes grupos.

**Ejemplo visual**:
```
Clasificar tumores: benigno vs maligno

TamaÃ±o
  â”‚
  â”‚  â— â— â—               â—‹ â—‹ â—‹
  â”‚    â— â—           â—‹ â—‹
  â”‚      â—     Frontera    â—‹
  â”‚           /         â—‹
  â”‚  â— â—    /      â—‹ â—‹
  â”‚      /    â—‹ â—‹
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Edad
  
  â— = Benigno (Clase 0)
  â—‹ = Maligno (Clase 1)
```

**Pregunta tÃ­pica**: "Â¿Este tumor es benigno o maligno?" â†’ Respuesta: Clase (benigno/maligno)

**Otros ejemplos**:
- Email: spam/no spam
- Imagen: gato/perro/pÃ¡jaro
- TransacciÃ³n: fraude/legÃ­tima

## 5.4.3 Importancia de las CaracterÃ­sticas
Aumentar el nÃºmero de caracterÃ­sticas **relevantes** mejora el aprendizaje.

**Ejemplo de clasificaciÃ³n de tumores**:

**Con 1 caracterÃ­stica** (solo tamaÃ±o):
```
DifÃ­cil separar benignos de malignos
```

**Con 2 caracterÃ­sticas** (tamaÃ±o + edad):
```
Mejor separaciÃ³n
```

**Con 3 caracterÃ­sticas** (tamaÃ±o + edad + densidad):
```
SeparaciÃ³n aÃºn mejor âœ…
```


# 5.5 RegresiÃ³n Lineal
La regresiÃ³n lineal es el algoritmo mÃ¡s bÃ¡sico de aprendizaje supervisado.

## 5.5.1 Componentes del Sistema
#### **NotaciÃ³n estÃ¡ndar**:

| SÃ­mbolo | Significado |
|---------|-------------|
| **m** | NÃºmero de ejemplos de entrenamiento |
| **n** | NÃºmero de caracterÃ­sticas (features) |
| **x** | Variables de entrada / caracterÃ­sticas |
| **y** | Variable de salida / respuesta |
| **(x, y)** | Un par entrada-salida genÃ©rico |
| **(xâ½â±â¾, yâ½â±â¾)** | El i-Ã©simo par entrada-salida |
| **xâ½â±â¾â±¼** | Valor de la caracterÃ­stica j en el ejemplo i |

## 5.5.2 Modelo de Aprendizaje

**Flujo del proceso**:

```
1. Conjunto de Entrenamiento
   â†“
2. Algoritmo de Aprendizaje
   â†“
3. HipÃ³tesis h (funciÃ³n aprendida)
   â†“
4. Para nueva entrada x â†’ h predice y
```



## 5.3 La HipÃ³tesis h
**Forma de la hipÃ³tesis** (regresiÃ³n lineal simple):

$$y=h_Î¸(x) = Î¸â‚€ + Î¸â‚Â·x$$

**Componentes**:
- **Î¸â‚€** (theta cero): Intercepto (valor cuando x=0)
- **Î¸â‚** (theta uno): Pendiente (inclinaciÃ³n de la recta)

**Ejemplo numÃ©rico**:

$$h_Î¸(x) = 50,000 + 2,000Â·x$$

```
InterpretaciÃ³n:
- Casa de 0 mÂ²: 50,000â‚¬ (base)
- Por cada mÂ² adicional: +2,000â‚¬
- Casa de 100 mÂ²: 50,000 + 2,000Ã—100 = 250,000â‚¬
```


## 5.5.4 FunciÃ³n de Coste J(Î¸)
**Objetivo**: Medir quÃ© tan bien se ajusta nuestra lÃ­nea a los datos.

**Concepto**: Queremos que nuestra predicciÃ³n $h_Î¸(x)$ estÃ© lo mÃ¡s cerca posible del valor real y.

**Error CuadrÃ¡tico Medio (MSE)**:
$$J(Î¸â‚€, Î¸â‚) = \frac{1}{2m} Ã— Î£(h_Î¸(xâ½â±â¾) - yâ½â±â¾)Â²$$

**Desglosando la fÃ³rmula**:
1. $h_Î¸(xâ½â±â¾)$: PredicciÃ³n para el ejemplo i
2. $yâ½â±â¾$: Valor real del ejemplo i
3. $(h_Î¸(xâ½â±â¾) - yâ½â±â¾)$: Error en el ejemplo i
4. $(...)Â²$: Elevamos al cuadrado (penaliza errores grandes)
5. $Î£$: Sumamos errores de todos los ejemplos
6. $\frac{1}{2m}$: Promediamos (el Â½ simplifica derivadas)

**Ejemplo numÃ©rico**:
```
Datos reales:
x = [50, 100, 150]
y = [150k, 250k, 350k]

Nuestra lÃ­nea: h_Î¸(x) = 50k + 2kÂ·x

Predicciones:
h_Î¸(50) = 150k  â†’ Error = (150k - 150k)Â² = 0
h_Î¸(100) = 250k â†’ Error = (250k - 250k)Â² = 0
h_Î¸(150) = 350k â†’ Error = (350k - 350k)Â² = 0

J(Î¸) = 0 âœ… Â¡Ajuste perfecto!
```


## 5.5.5 Descenso de Gradiente
**Objetivo**: Encontrar los valores de Î¸ que **minimizan J(Î¸)**.
**Concepto visual**: Imagina que estÃ¡s en una montaÃ±a y quieres bajar al valle (mÃ­nimo).

```
        ğŸ”ï¸ â† Valor alto de J(Î¸)
       /  \
      /    \
     /      \
    /        \
   /    ğŸš¶    \
  /   â†“ bajas  \
 /      â†“       \
/________ğŸ¯______\ â† MÃ­nimo (mejor Î¸)
```

![](./Pasted image 20251103114208.png)

**Algoritmo** (repetir hasta convergencia):

$$Î¸â±¼ := Î¸â±¼ - Î± Ã— \frac{âˆ‚J}{âˆ‚Î¸â±¼}$$

Donde:
- $Î±$ (alpha): Tasa de aprendizaje (tamaÃ±o del paso)
- $\frac{âˆ‚J}{âˆ‚Î¸â±¼}$: Derivada parcial (direcciÃ³n del descenso)

**Forma especÃ­fica para regresiÃ³n lineal**:
$$Î¸_0 := Î¸_0 - Î± Ã— \frac{âˆ‚}{âˆ‚Î¸_0} \times J(\theta_0,\theta_1)$$
$$Î¸_1 := Î¸_1 - Î± Ã— \frac{âˆ‚}{âˆ‚Î¸_1} \times J(\theta_0,\theta_1)$$

$$\frac{âˆ‚}{âˆ‚Î¸_j} \times J(\theta_0,\theta_1) = J(Î¸â‚€, Î¸â‚) = \frac{âˆ‚}{âˆ‚Î¸_j} \times \frac{1}{2m} Ã— Î£(h_Î¸(xâ½â±â¾) - yâ½â±â¾)Â²=\frac{âˆ‚}{âˆ‚Î¸_j} \times \frac{1}{2m} Ã— Î£(\theta_0 + \theta_1x^{(i)} - yâ½â±â¾)Â²$$
$$j=0: \frac{âˆ‚}{âˆ‚Î¸_0} \times J(\theta_0,\theta_1)= \frac{1}{m} Ã— Î£(h_Î¸(xâ½â±â¾) - yâ½â±â¾)$$
$$j=1: \frac{âˆ‚}{âˆ‚Î¸_1} \times J(\theta_0,\theta_1)= \frac{1}{m} Ã— Î£(h_Î¸(xâ½â±â¾) - yâ½â±â¾)\times x^{(i)}$$


## 5.5.6 Ejemplo Paso a Paso
**Problema**: Predecir precio de casas segÃºn tamaÃ±o.

**Datos de entrenamiento** (m=3):
```
x (mÂ²)  | y (precio â‚¬)
--------|-------------
50      | 150,000
100     | 250,000
150     | 350,000
```

**Paso 1: Inicializar parÃ¡metros**
```
Î¸â‚€ = 0
Î¸â‚ = 0
Î± = 0.01 (tasa de aprendizaje)
```

**Paso 2: Primera predicciÃ³n**
```
h_Î¸(x) = 0 + 0Â·x = 0 (para todos los x)
```

**Paso 3: Calcular coste inicial**
```
J(Î¸) = (1/6) Ã— [(0-150k)Â² + (0-250k)Â² + (0-350k)Â²]
     = (1/6) Ã— [22,500M + 62,500M + 122,500M]
     = 34,583M â† Â¡Muy alto! âŒ
```

**Paso 4: Calcular gradientes y actualizar Î¸**
```
âˆ‚J/âˆ‚Î¸â‚€ = (1/3) Ã— [(0-150k) + (0-250k) + (0-350k)]
       = -250,000

âˆ‚J/âˆ‚Î¸â‚ = (1/3) Ã— [(0-150k)Ã—50 + (0-250k)Ã—100 + (0-350k)Ã—150]
       = -30,000,000

Î¸â‚€ := 0 - 0.01 Ã— (-250,000) = 2,500
Î¸â‚ := 0 - 0.01 Ã— (-30,000,000) = 300,000
```

**Paso 5: Nueva predicciÃ³n**
```
h_Î¸(x) = 2,500 + 300,000Â·x
```

**Repetir** pasos 3-4 hasta que J(Î¸) deje de disminuir significativamente.



## 5.5.7 Tasa de Aprendizaje Î±
**Concepto**: Controla el tamaÃ±o de los pasos al descender.

| Valor de Î± | Efecto | Problema |
|------------|--------|----------|
| **Muy pequeÃ±o** (0.001) | Pasos muy pequeÃ±os | Convergencia MUY lenta ğŸŒ |
| **Adecuado** (0.01-0.1) | Pasos balanceados | Convergencia Ã³ptima âœ… |
| **Muy grande** (10) | Pasos muy grandes | Puede no converger (oscila) âŒ |

**VisualizaciÃ³n del efecto de Î±**:

```
Î± muy pequeÃ±o:
J(Î¸)
  â”‚â—
  â”‚ â—
  â”‚  â—
  â”‚   â—    â† Baja muy lentamente
  â”‚    â—
  â””â”€â”€â”€â”€â”€â”€â”€â”€> Iteraciones

Î± muy grande:
J(Î¸)
  â”‚  â—
  â”‚    â—
  â”‚ â—
  â”‚      â— â† Oscila, no converge
  â”‚   â—
  â””â”€â”€â”€â”€â”€â”€â”€â”€> Iteraciones

Î± adecuado:
J(Î¸)
  â”‚â—
  â”‚  â—
  â”‚    â—
  â”‚      â— â† Converge rÃ¡pidamente
  â”‚       â—___
  â””â”€â”€â”€â”€â”€â”€â”€â”€> Iteraciones
```


# 5.6 RegresiÃ³n Lineal Multivariable
Hasta ahora: 1 caracterÃ­stica (tamaÃ±o de casa)
Ahora: MÃºltiples caracterÃ­sticas (tamaÃ±o, habitaciones, edad, etc.)

## 5.6.1 NotaciÃ³n Extendida

**Nueva forma de h**:

```
h_Î¸(x) = Î¸â‚€ + Î¸â‚xâ‚ + Î¸â‚‚xâ‚‚ + ... + Î¸â‚™xâ‚™

En forma vectorial:
h_Î¸(x) = Î¸áµ€ Ã— x

Donde:
Î¸ = [Î¸â‚€, Î¸â‚, Î¸â‚‚, ..., Î¸â‚™]áµ€
x = [1, xâ‚, xâ‚‚, ..., xâ‚™]áµ€  (xâ‚€ = 1 por convenciÃ³n)
```

## 5.6.2 Ejemplo con 3 caracterÃ­sticas

**PredicciÃ³n de precio de casa**:

```
CaracterÃ­sticas:
xâ‚ = TamaÃ±o (mÂ²)
xâ‚‚ = NÃºmero de habitaciones
xâ‚ƒ = Edad (aÃ±os)

h_Î¸(x) = Î¸â‚€ + Î¸â‚Â·tamaÃ±o + Î¸â‚‚Â·habitaciones + Î¸â‚ƒÂ·edad

Ejemplo con valores aprendidos:
h_Î¸(x) = 80,000 + 2,000Â·tamaÃ±o + 10,000Â·habitaciones - 1,000Â·edad

Para una casa de 100mÂ², 3 habitaciones, 5 aÃ±os:
h_Î¸(x) = 80,000 + 2,000Ã—100 + 10,000Ã—3 - 1,000Ã—5
       = 80,000 + 200,000 + 30,000 - 5,000
       = 305,000â‚¬
```


### 6.3 NormalizaciÃ³n de CaracterÃ­sticas
Si las caracterÃ­sticas tienen rangos muy diferentes, el descenso de gradiente converge lentamente.

**Ejemplo**:
```
xâ‚ = TamaÃ±o: rango [50 - 200]
xâ‚‚ = Habitaciones: rango [1 - 5]
```

**SoluciÃ³n: Feature Scaling**

```
x_j^(i) := (x_j^(i) - Î¼â±¼) / sâ±¼

Donde:
Î¼â±¼ = media de la caracterÃ­stica j
sâ±¼ = desviaciÃ³n estÃ¡ndar de la caracterÃ­stica j
```

**Ejemplo numÃ©rico**:

```
Original xâ‚ (tamaÃ±o): [50, 100, 150, 200]
Î¼â‚ = (50+100+150+200)/4 = 125
sâ‚ = desviaciÃ³n = 55.9

Normalizado:
xâ‚ = [50-125]/55.9 = -1.34
xâ‚ = [100-125]/55.9 = -0.45
xâ‚ = [150-125]/55.9 = 0.45
xâ‚ = [200-125]/55.9 = 1.34

Ahora todos estÃ¡n aproximadamente en el rango [-2, 2] âœ…
```


## 5.6.4 EcuaciÃ³n Normal (MÃ©todo AnalÃ­tico)

**Alternativa al descenso de gradiente**: Calcular Î¸ directamente con Ã¡lgebra lineal.

**FÃ³rmula**:
```
Î¸ = (Xáµ€X)â»Â¹ Xáµ€y

Donde:
X = matriz de caracterÃ­sticas (m Ã— n+1)
y = vector de salidas (m Ã— 1)
```

**ComparaciÃ³n con Descenso de Gradiente**:

| Descenso de Gradiente                   | EcuaciÃ³n Normal          |
| --------------------------------------- | ------------------------ |
| Necesita elegir Î±                       | No necesita Î± âœ…          |
| Necesita muchas iteraciones             | Sin iteraciones âœ…        |
| Funciona bien con n grande (millones) âœ… | Lento con n > 10,000 âŒ   |
| Necesita normalizar features            | No necesita normalizar âœ… |
| Complejidad O(knÂ²)                      | Complejidad O(nÂ³)        |



# 5.7 RegresiÃ³n LogÃ­stica
**Objetivo**: Resolver problemas de **clasificaciÃ³n** (no regresiÃ³n, a pesar del nombre).

## 5.7.1 Â¿Por quÃ© no usar regresiÃ³n lineal para clasificaciÃ³n?
**Problema visual**:

```
Clasificar tumor: 0 (benigno) o 1 (maligno)

y
1â”‚          â—‹  â—‹  â—‹   â† Malignos
 â”‚      â— â—            â† Benignos
0â”‚  â— â—                
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> TamaÃ±o

Si usamos regresiÃ³n lineal:
1â”‚              â•±â—‹  â—‹  â—‹
 â”‚          â•±   
0â”‚  â— â— â•±              
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>

Problemas:
- h(x) puede ser > 1 o < 0 âŒ
- Un tumor MUY grande altera toda la lÃ­nea âŒ
```


## 5.7.2 FunciÃ³n Sigmoide (LogÃ­stica)
**SoluciÃ³n**: Usar una funciÃ³n que siempre devuelva valores entre 0 y 1.

**FÃ³rmula**:

```
g(z) = 1 / (1 + eâ»á¶»)

h_Î¸(x) = g(Î¸áµ€x) = 1 / (1 + e^(-Î¸áµ€x))
```

**GrÃ¡fica**:

```
g(z)
  1â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€
   â”‚       /
 0.5â”‚      / â† Umbral
   â”‚     /
  0â”‚â”€â”€â”€â”€â”˜
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> z
  -âˆ   0   +âˆ
  
z >> 0 â†’ g(z) â‰ˆ 1
z = 0  â†’ g(z) = 0.5
z << 0 â†’ g(z) â‰ˆ 0
```

**InterpretaciÃ³n**:

```
h_Î¸(x) = 0.7

Significa: "Hay un 70% de probabilidad de que y=1"
```


## 5.7.3 Frontera de DecisiÃ³n
**Regla de decisiÃ³n**:
```
Si h_Î¸(x) â‰¥ 0.5 â†’ predecir y=1
Si h_Î¸(x) < 0.5 â†’ predecir y=0

Como g(z) â‰¥ 0.5 cuando z â‰¥ 0:
Si Î¸áµ€x â‰¥ 0 â†’ predecir y=1
Si Î¸áµ€x < 0 â†’ predecir y=0
```

#### **Ejemplo 1: Frontera lineal**

```
h_Î¸(x) = g(-3 + xâ‚ + xâ‚‚)

Predecir y=1 cuando: -3 + xâ‚ + xâ‚‚ â‰¥ 0
Es decir: xâ‚ + xâ‚‚ â‰¥ 3

GrÃ¡fica:
xâ‚‚
  â”‚       y=1 (â—‹â—‹â—‹)
 3â”‚      /
  â”‚     / â† Frontera: xâ‚ + xâ‚‚ = 3
  â”‚    /
  â”‚   / y=0 (â—â—â—)
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> xâ‚
     3
```

#### **Ejemplo 2: Frontera circular**

```
h_Î¸(x) = g(-1 + xâ‚Â² + xâ‚‚Â²)

Predecir y=1 cuando: xâ‚Â² + xâ‚‚Â² â‰¥ 1

GrÃ¡fica:
xâ‚‚
  â”‚    â—‹ â—‹ â—‹ â—‹
  â”‚  â—‹ â—â”€â”€â”€â”€â”€â— â—‹
  â”‚  â—‹ â”‚  0  â”‚ â—‹  â† CÃ­rculo de radio 1
  â”‚  â—‹ â—â”€â”€â”€â”€â”€â— â—‹
  â”‚    â—‹ â—‹ â—‹ â—‹
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> xâ‚

Interior (â—): y=0
Exterior (â—‹): y=1
```


## 5.7.4 FunciÃ³n de Coste para RegresiÃ³n LogÃ­stica

**Problema**: El error cuadrÃ¡tico hace que J(Î¸) sea no convexa (mÃºltiples mÃ­nimos).

**SoluciÃ³n**: Nueva funciÃ³n de coste:

```
Cost(h_Î¸(x), y) = -log(h_Î¸(x))        si y=1
Cost(h_Î¸(x), y) = -log(1 - h_Î¸(x))   si y=0

Forma compacta:
Cost(h_Î¸(x), y) = -yÂ·log(h_Î¸(x)) - (1-y)Â·log(1-h_Î¸(x))

FunciÃ³n de coste total:
J(Î¸) = -(1/m) Î£ [yâ½â±â¾Â·log(h_Î¸(xâ½â±â¾)) + (1-yâ½â±â¾)Â·log(1-h_Î¸(xâ½â±â¾))]
```

**IntuiciÃ³n**:

```
Si y=1:
- h_Î¸(x) = 1 â†’ Cost = -log(1) = 0 âœ… Sin penalizaciÃ³n
- h_Î¸(x) = 0.5 â†’ Cost = -log(0.5) = 0.69
- h_Î¸(x) = 0.1 â†’ Cost = -log(0.1) = 2.3 âŒ PenalizaciÃ³n alta

Si y=0:
- h_Î¸(x) = 0 â†’ Cost = -log(1) = 0 âœ… Sin penalizaciÃ³n
- h_Î¸(x) = 0.5 â†’ Cost = -log(0.5) = 0.69
- h_Î¸(x) = 0.9 â†’ Cost = -log(0.1) = 2.3 âŒ PenalizaciÃ³n alta
```


## 5.7.5 Algoritmo de Descenso de Gradiente

**ActualizaciÃ³n** (Â¡idÃ©ntica en forma a regresiÃ³n lineal!):

```
Î¸â±¼ := Î¸â±¼ - Î± Ã— (1/m) Ã— Î£[h_Î¸(xâ½â±â¾) - yâ½â±â¾] Ã— xâ±¼â½â±â¾

Pero recuerda:
h_Î¸(x) = 1/(1 + e^(-Î¸áµ€x))  â† Diferente de regresiÃ³n lineal
```

---

### 7.6 ClasificaciÃ³n Multiclase

**Estrategia**: One-vs-All (uno contra todos)

**Proceso**:

```
Problema: Clasificar emails en 3 categorÃ­as
- Clase 1: Personal
- Clase 2: Trabajo
- Clase 3: Spam

Entrenamos 3 clasificadores:

Clasificador 1: Â¿Es Personal? (sÃ­ vs no)
Clasificador 2: Â¿Es Trabajo? (sÃ­ vs no)
Clasificador 3: Â¿Es Spam? (sÃ­ vs no)

Para un nuevo email:
hâ‚(x) = 0.2 (20% probabilidad Personal)
hâ‚‚(x) = 0.7 (70% probabilidad Trabajo) â† Â¡MÃ¡ximo!
hâ‚ƒ(x) = 0.1 (10% probabilidad Spam)

PredicciÃ³n final: Trabajo âœ…
```


# 5.8 RegresiÃ³n PolinÃ³mica
**Objetivo**: Ajustar curvas (no solo lÃ­neas rectas).

**Idea**: Crear nuevas caracterÃ­sticas elevando las originales a potencias.

```
Original:
h_Î¸(x) = Î¸â‚€ + Î¸â‚x

CuadrÃ¡tica:
h_Î¸(x) = Î¸â‚€ + Î¸â‚x + Î¸â‚‚xÂ²

CÃºbica:
h_Î¸(x) = Î¸â‚€ + Î¸â‚x + Î¸â‚‚xÂ² + Î¸â‚ƒxÂ³
```

**Ejemplo visual**:

```
Precio de casa segÃºn tamaÃ±o

Lineal:        CuadrÃ¡tica:       CÃºbica:
  â”‚  â—           â”‚    â—              â”‚    â—
  â”‚â—  â—          â”‚ â—   â—             â”‚ â—   â—
  â”‚ â—            â”‚â—     â—            â”‚â—â”€â”€â”€â”€â”€â—
  â”‚  â—           â”‚       â—           â”‚       â•²
  â”‚   â—          â”‚        â—          â”‚        â—
  â””â”€â”€â”€â”€>         â””â”€â”€â”€â”€>               â””â”€â”€â”€â”€>

Simple         Mejor ajuste        Puede sobreajustar
```



# 5.9 Overfitting (Sobreajuste)

## 5.9.1 Los Tres Escenarios

**Ejemplo con regresiÃ³n**:

```
UNDERFITTING         GOOD FIT         OVERFITTING
(Subajuste)         (Buen ajuste)     (Sobreajuste)

   â—                    â—                  â—
  â— â—                 â—   â—              â—â•± â•²â—
 â—   â—               â—â”€â”€â”€â”€â”€â—            â—â•±   â•²â—
â—     â—             â—       â—          â—â•±     â•²â—
â”€â”€â”€â”€â”€â”€â”€             â”€â”€â”€â”€â”€â”€â”€â”€â”€          â—â”€â”€â”€â”€â”€â”€â”€â—

h(x)=Î¸â‚€+Î¸â‚x      h(x)=Î¸â‚€+Î¸â‚x+Î¸â‚‚xÂ²   h(x)=Î¸â‚€+...+Î¸â‚…xâµ

Sesgo alto          Balance âœ…         Varianza alta
No captura          Captura             Captura el ruido
el patrÃ³n           el patrÃ³n           tambiÃ©n
```

**Ejemplo con clasificaciÃ³n**:

```
UNDERFITTING         GOOD FIT         OVERFITTING

â—â—â—â”‚â—‹â—‹â—‹            â—â—â— â”‚ â—‹â—‹â—‹         â—â—â—â•±â•²â—‹â—‹â—‹
â—â—â—â”‚â—‹â—‹â—‹            â—â—â—â”€â•¯ â—‹â—‹â—‹         â—â—â•±  â•²â—‹â—‹
â—â—â—â”‚â—‹â—‹â—‹            â—â—â—   â—‹â—‹â—‹         â—â•±â”€â”€â”€â”€â•²â—‹

LÃ­nea recta         Curva suave       Frontera errÃ¡tica
muy simple          apropiada âœ…      se ajusta al ruido
```


## 5.9.2 Soluciones al Overfitting

#### **SoluciÃ³n 1: Reducir nÃºmero de caracterÃ­sticas**
```
Manualmente:
- Eliminar caracterÃ­sticas poco relevantes

AutomÃ¡ticamente:
- Algoritmos de selecciÃ³n de caracterÃ­sticas
```

#### **SoluciÃ³n 2: RegularizaciÃ³n**
**Concepto**: Penalizar parÃ¡metros Î¸ muy grandes.

**Nueva funciÃ³n de coste**:

```
J(Î¸) = [coste original] + Î»/(2m) Ã— Î£Î¸â±¼Â²
                           â””â”€â”€ TÃ©rmino de regularizaciÃ³n

Donde:
Î» (lambda) = parÃ¡metro de regularizaciÃ³n
```

**Efecto**:

```
Î» = 0:        Sin regularizaciÃ³n â†’ Posible overfitting
Î» pequeÃ±o:    Poca regularizaciÃ³n â†’ Balance
Î» grande:     Mucha regularizaciÃ³n â†’ Posible underfitting

Ejemplo:
Si Î» es muy grande, forzamos todos los Î¸â±¼ â‰ˆ 0
Resultado: h(x) â‰ˆ Î¸â‚€ (funciÃ³n constante) â†’ Underfitting
```

**RegresiÃ³n lineal regularizada**:

```
Î¸â±¼ := Î¸â±¼ - Î± Ã— [(1/m)Î£(h_Î¸(xâ½â±â¾)-yâ½â±â¾)xâ±¼â½â±â¾ + (Î»/m)Î¸â±¼]
                â””â”€â”€ tÃ©rmino original â”€â”€â”˜  â””â”€ regularizaciÃ³n â”€â”˜
```

# 5.10 Flujo Completo de un Proyecto de ML

```
1. DEFINIR EL PROBLEMA
   Â¿RegresiÃ³n o ClasificaciÃ³n?
        â†“
2. RECOPILAR DATOS
   Conjunto de entrenamiento (x, y)
        â†“
3. PREPROCESAR DATOS
   - Limpiar datos
   - Normalizar caracterÃ­sticas
   - Dividir en entrenamiento/test
        â†“
4. ELEGIR MODELO
   - RegresiÃ³n lineal
   - RegresiÃ³n logÃ­stica
   - Otro algoritmo
        â†“
5. ENTRENAR MODELO
   - Inicializar Î¸
   - Minimizar J(Î¸) con descenso de gradiente
        â†“
6. EVALUAR MODELO
   - Probar en datos de test
   - Verificar overfitting/underfitting
        â†“
7. AJUSTAR Y MEJORAR
   - Cambiar Î±
   - AÃ±adir/quitar caracterÃ­sticas
   - Aplicar regularizaciÃ³n
        â†“
8. DESPLEGAR
   Usar el modelo en producciÃ³n
```
